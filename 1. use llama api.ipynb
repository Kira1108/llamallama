{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Call Llama from official LlamaAPI Page\n",
    "   \n",
    "\n",
    "LlamaAPI本身是支持function calling的，所以openai function这个功能在LLama同样好用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llamaapi                                 0.1.36\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep llamaapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.36'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import llamaapi\n",
    "\n",
    "llamaapi.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "LLAMA_API_KEY = os.getenv(\"LLAMA_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"get_current_weather\",\n",
      "          \"arguments\": {\n",
      "            \"location\": \"Boston\",\n",
      "            \"days\": 5,\n",
      "            \"unit\": \"celsius\"\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from llamaapi import LlamaAPI\n",
    "\n",
    "# Initialize the SDK\n",
    "llama = LlamaAPI(LLAMA_API_KEY)\n",
    "\n",
    "# Build the API request\n",
    "api_request_json = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is the weather like in Boston?\"},\n",
    "    ],\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"days\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"for how many days ahead you wants the forecast\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\", \"days\"],\n",
    "        }\n",
    "    ],\n",
    "    \"stream\": False,\n",
    "    \"function_call\": \"get_current_weather\",\n",
    "}\n",
    "\n",
    "# Execute the Request\n",
    "response = llama.run(api_request_json)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': None,\n",
       "    'function_call': {'name': 'get_current_weather',\n",
       "     'arguments': {'location': 'Boston', 'days': 5, 'unit': 'celsius'}}},\n",
       "   'finish_reason': 'function_call'}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Call Llama from Llama Index   \n",
    "\n",
    "为了跟RAG框架Llama Index兼容，有时候需要Llama Index调用LlamaAPI，用下面的接口，无非是API的改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9.7'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import llama_index\n",
    "\n",
    "llama_index.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.llama_api import LlamaAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LlamaAPI(api_key=LLAMA_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What is your name\"),\n",
    "]\n",
    "\n",
    "resp = llm.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrrr, me hearty! Me name be Captain Blackbeak, the most feared and infamous pirate to ever sail the seven seas! Yer lookin' at the scurviest dog in all the land, the one and only Captain Blackbeak! *adjusts eye patch*\n",
      "\n",
      "So, what be bringin' ye to these waters, matey? Are ye here to plunder some booty or just to taste the salty sea air? Either way, I be ready to help ye find yer treasure, or at least a good bottle o' grog! *winks*\n"
     ]
    }
   ],
   "source": [
    "print(resp.message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
